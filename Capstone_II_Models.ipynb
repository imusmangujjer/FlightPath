{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be9d97d",
   "metadata": {},
   "source": [
    "## **Importing necessary package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078d5fe",
   "metadata": {},
   "source": [
    "# **1. Data Exploratory:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7202d59",
   "metadata": {},
   "source": [
    "## **1-a. Variables/ Data fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/drive/MyDrive/capstone1/All_Airlines/feature image 1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89730cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('/content/drive/MyDrive/capstone1/All_Airlines/feature image 2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d5040",
   "metadata": {},
   "source": [
    "## **1-b. reviewing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreving data\n",
    "\n",
    "df = pd.read_csv('all_airlines.csv')\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f62d4",
   "metadata": {},
   "source": [
    "# **6. Baseline Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8118432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceeding with the sampled data for model training and prediction\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Feature Engineering\n",
    "# Selecting relevant features for regression\n",
    "features = [\n",
    "    \"Carrier Code\", \"Flight Number\", \"Origin Airport\", \"Destination Airport\",\n",
    "    \"Scheduled elapsed time (Minutes)\", \"Day\", \"Month\", \"Year\", 'Delay Carrier (Minutes)', 'Taxi-Out time (Minutes)', 'Taxi-In time (Minutes)',\n",
    "    'Departure delay (Minutes)', 'Delay Weather (Minutes)',\n",
    "    'Delay National Aviation System (Minutes)', 'Delay Security (Minutes)',\n",
    "    'Delay Late Aircraft Arrival (Minutes)', 'Actual Elapsed Time (Minutes)'\n",
    "]\n",
    "target = \"Arrival Delay (Minutes)\"\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in [\"Carrier Code\", \"Origin Airport\", \"Destination Airport\"]:\n",
    "    le = LabelEncoder()\n",
    "    df_new[col] = le.fit_transform(df_new[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "X = df_new[features]\n",
    "y = df_new[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Train a Regression Model\n",
    "regressor = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate the Model\n",
    "y_pred = regressor.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "evaluation_results = {\n",
    "    \"Mean Absolute Error (MAE)\": mae,\n",
    "    \"Mean Squared Error (MSE)\": mse,\n",
    "    \"R^2 Score\": r2\n",
    "}\n",
    "\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753073f2",
   "metadata": {},
   "source": [
    "# **Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb56f09",
   "metadata": {},
   "source": [
    "### Embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'regressor' and 'features' are already defined from the previous code\n",
    "\n",
    "# Get feature importances\n",
    "importances = regressor.feature_importances_\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importances = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances)\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Print feature importances in descending order\n",
    "print(\"Feature Importances:\")\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a1f8e",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_columns = df_new.select_dtypes(include=['float64', 'int64', 'int32'])\n",
    "\n",
    "# Compute the correlation matrix for numeric columns\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', cbar=True)\n",
    "plt.title(\"Correlation Matrix for All Numeric Variables\")\n",
    "plt.show()\n",
    "\n",
    "# Focus on the correlation with \"Arrival Delay (Minutes)\"\n",
    "arrival_delay_corr = correlation_matrix['Arrival Delay (Minutes)'].sort_values(ascending=False)\n",
    "arrival_delay_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dc2dc",
   "metadata": {},
   "source": [
    "### Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define feature columns\n",
    "features = [\"Day\", \"Month\", \"Year\",'Carrier Code',\n",
    "       'Origin Airport', 'Destination Airport',\n",
    "       'Departure delay (Minutes)',\n",
    "       'Taxi-Out time (Minutes)', 'Delay Carrier (Minutes)',\n",
    "       'Delay Weather (Minutes)', 'Delay National Aviation System (Minutes)',\n",
    "       'Delay Security (Minutes)', 'Delay Late Aircraft Arrival (Minutes)',\n",
    "       'Scheduled Elapsed Time (Minutes)', 'Actual Elapsed Time (Minutes)',\n",
    "       'Taxi-In time (Minutes)']\n",
    "target = \"Arrival Delay (Minutes)\"\n",
    "\n",
    "# Splitting the dataset\n",
    "X = df_new[features]\n",
    "y = df_new[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# List of categorical columns\n",
    "categorical_cols = [\"Carrier Code\", \"Origin Airport\", \"Destination Airport\"]\n",
    "\n",
    "# Apply Label Encoding for Carrier Code (Binary)\n",
    "label_encoders = {}\n",
    "le = LabelEncoder()\n",
    "X_train[\"Carrier Code\"] = le.fit_transform(X_train[\"Carrier Code\"])\n",
    "X_test[\"Carrier Code\"] = le.transform(X_test[\"Carrier Code\"])\n",
    "label_encoders[\"Carrier Code\"] = le\n",
    "\n",
    "# Apply Frequency Encoding for Origin and Destination Airports\n",
    "for col in [\"Origin Airport\", \"Destination Airport\"]:\n",
    "    freq_map = X_train[col].value_counts().to_dict()  # Compute frequency\n",
    "    X_train[col] = X_train[col].map(freq_map)\n",
    "    X_test[col] = X_test[col].map(freq_map)  # Use same mapping for test data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Linear Regression Model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Apply Recursive Feature Elimination (RFE) to select the top 10 features\n",
    "rfe = RFE(model, n_features_to_select=10)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# Train the model with selected features\n",
    "model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Model Predictions\n",
    "y_pred = model.predict(X_test_rfe)\n",
    "\n",
    "# Evaluate Performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Extract selected feature names and coefficients\n",
    "selected_features = np.array(X.columns)[rfe.support_]\n",
    "feature_coefficients = model.coef_\n",
    "\n",
    "# Create a DataFrame to display selected features with their coefficients\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": selected_features,\n",
    "    \"Coefficient\": feature_coefficients\n",
    "}).sort_values(by=\"Coefficient\", ascending=False)\n",
    "\n",
    "# Display evaluation metrics and feature importance\n",
    "evaluation_results = {\n",
    "    \"Selected Features\": selected_features.tolist(),\n",
    "    \"Mean Absolute Error (MAE)\": mae,\n",
    "    \"Mean Squared Error (MSE)\": mse,\n",
    "    \"R^2 Score\": r2\n",
    "}\n",
    "\n",
    "# Show the evaluation results\n",
    "print(evaluation_results)\n",
    "\n",
    "# Display feature coefficients\n",
    "print(\"\\nFeature Coefficients:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d1877",
   "metadata": {},
   "source": [
    "# **Final Model after Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e97bf20",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54902064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = [\"Day\", \"Month\", \"Year\", \"Taxi-Out time (Minutes)\", \"Taxi-In time (Minutes)\",\n",
    "            \"Origin Airport\", \"Carrier Code\", \"Destination Airport\",\n",
    "            \"Scheduled Elapsed Time (Minutes)\",\n",
    "            \"Actual Elapsed Time (Minutes)\",\n",
    "            \"Departure delay (Minutes)\",\n",
    "            \"Scheduled departure hour\"]\n",
    "target = \"Arrival Delay (Minutes)\"\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in [\"Carrier Code\", \"Origin Airport\", \"Destination Airport\"]:\n",
    "    le = LabelEncoder()\n",
    "    df_new[col] = le.fit_transform(df_new[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "X = df_new[features]\n",
    "y = df_new[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Train the Random Forest Model\n",
    "regressor = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=100,  # Increase trees for better learning\n",
    "    max_depth=15,  # Allow deeper trees for more complex patterns\n",
    "    min_samples_split=4,  # Slightly reduce min samples per split\n",
    "    min_samples_leaf=2  # Slightly reduce min samples per leaf\n",
    ")\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = regressor.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "evaluation_results = {\n",
    "    \"Mean Absolute Error (MAE)\": mae,\n",
    "    \"Mean Squared Error (MSE)\": mse,\n",
    "    \"R^2 Score\": r2\n",
    "}\n",
    "\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d61a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = regressor.predict(X_train)\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\n",
    "print(f\"Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r2 = regressor.score(X_train, y_train)\n",
    "test_r2 = regressor.score(X_test, y_test)\n",
    "\n",
    "print(f\"Training RÂ²: {train_r2:.4f}\")\n",
    "print(f\"Testing RÂ²: {test_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23cdeef",
   "metadata": {},
   "source": [
    "### XGBoost with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Ensure all categorical columns are encoded\n",
    "categorical_features = [\"Origin Airport\", \"Carrier Code\", \"Destination Airport\"]\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_new[col] = le.fit_transform(df_new[col])\n",
    "    label_encoders[col] = le  # Store encoders in case you need them later\n",
    "\n",
    "\n",
    "# Define features and target\n",
    "features = [\"Day\", \"Month\", \"Year\", \"Taxi-Out time (Minutes)\", \"Taxi-In time (Minutes)\",\n",
    "            \"Origin Airport\", \"Carrier Code\", \"Destination Airport\",\n",
    "            \"Scheduled Elapsed Time (Minutes)\",\n",
    "            \"Scheduled departure hour\",\n",
    "            \"Departure delay (Minutes)\", \"Actual Elapsed Time (Minutes)\"]\n",
    "target = \"Arrival Delay (Minutes)\"\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "X = df_new[features]\n",
    "y = df_new[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost Model\n",
    "regressor = XGBRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=1200,  # Keep high for stability\n",
    "    max_depth=10,  # Slightly reduce tree complexity\n",
    "    learning_rate=0.01,  # Lower learning rate for fine-tuned updates\n",
    "    reg_lambda=7,  # Moderate L2 regularization\n",
    "    reg_alpha=4,  # Stronger L1 regularization to remove noise\n",
    "    gamma=4,  # Prune unnecessary splits\n",
    "    subsample=0.85,  # Ensure generalization\n",
    "    colsample_bytree=0.9  # Use 90% of features per tree\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = regressor.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "evaluation_results = {\n",
    "    \"Mean Absolute Error (MAE)\": mae,\n",
    "    \"Mean Squared Error (MSE)\": mse,\n",
    "    \"R^2 Score\": r2\n",
    "}\n",
    "\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c99f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Ensure all categorical columns are encoded\n",
    "categorical_features = [\"Origin Airport\", \"Carrier Code\", \"Destination Airport\"]\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df_new[col] = le.fit_transform(df_new[col])\n",
    "    label_encoders[col] = le  # Store encoders in case you need them later\n",
    "\n",
    "# Define features and target\n",
    "features = [\"Day\", \"Month\", \"Year\", \"Taxi-Out time (Minutes)\", \"Taxi-In time (Minutes)\",\n",
    "            \"Origin Airport\", \"Carrier Code\", \"Destination Airport\",\n",
    "            \"Scheduled Elapsed Time (Minutes)\", \"Scheduled departure hour\",\n",
    "            \"Departure delay (Minutes)\", \"Actual Elapsed Time (Minutes)\"]\n",
    "target = \"Arrival Delay (Minutes)\"\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "X = df_new[features]\n",
    "y = df_new[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost Model\n",
    "regressor = XGBRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=1200,  # Keep high for stability\n",
    "    max_depth=20,  # Slightly reduce tree complexity\n",
    "    learning_rate=0.02,  # Lower learning rate for fine-tuned updates\n",
    "    reg_lambda=7,  # Moderate L2 regularization\n",
    "    reg_alpha=4,  # Stronger L1 regularization to remove noise\n",
    "    gamma=4,  # Prune unnecessary splits\n",
    "    subsample=0.85,  # Ensure generalization\n",
    "    colsample_bytree=0.9  # Use 90% of features per tree\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(regressor, \"best_XGB_Regression_model.pkl\")\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred = regressor.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "evaluation_results = {\n",
    "    \"Mean Absolute Error (MAE)\": mae,\n",
    "    \"Mean Squared Error (MSE)\": mse,\n",
    "    \"R^2 Score\": r2\n",
    "}\n",
    "\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a43ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = regressor.predict(X_train)\n",
    "\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\n",
    "print(f\"Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r2 = regressor.score(X_train, y_train)\n",
    "test_r2 = regressor.score(X_test, y_test)\n",
    "\n",
    "print(f\"Training RÂ²: {train_r2:.4f}\")\n",
    "print(f\"Testing RÂ²: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2605284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute correlation\n",
    "correlation = df_new[['Arrival Delay (Minutes)', 'Departure delay (Minutes)']].corr()\n",
    "print(correlation)\n",
    "\n",
    "# Visualize correlation\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(correlation, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Between Arrival Delay & Departure Delay\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a6d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b565b11",
   "metadata": {},
   "source": [
    "# **PyCaret**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29252e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y pycaret scikit-plot scipy\n",
    "!pip install --no-cache-dir scipy==1.9.3\n",
    "!pip install --no-cache-dir scikit-plot\n",
    "!pip install --no-cache-dir pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86447f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.regression import *\n",
    "\n",
    "# Load the dataset\n",
    "#file_path = \"/content/df_new.csv\"  # Adjust the file path if needed\n",
    "df = df.copy()\n",
    "\n",
    "# Define the target and features\n",
    "target = \"Arrival Delay (Minutes)\"\n",
    "features = [\"Day\", \"Month\", \"Year\", \"Taxi-Out time (Minutes)\", \"Taxi-In time (Minutes)\", \"Scheduled Elapsed Time (Minutes)\",\n",
    "            \"Origin Airport\", \"Carrier Code\", \"Destination Airport\",\n",
    "            \"Scheduled departure hour\", \"Departure delay (Minutes)\"]\n",
    "\n",
    "# Select only the required columns\n",
    "df = df[features + [target]]\n",
    "\n",
    "# Initialize PyCaret for regression\n",
    "exp_reg = setup(data=df, target=target, session_id=123,\n",
    "    normalize=True, categorical_features=[\"Origin Airport\", \"Carrier Code\", \"Destination Airport\"],encoding_method=\"onehot\")\n",
    "\n",
    "\n",
    "# Save the best model\n",
    "best_model = compare_models()\n",
    "save_model(best_model, \"best_regression_model\")\n",
    "\n",
    "print(\"\\nBest model saved as 'best_regression_model'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a279d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f737b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute correlation\n",
    "correlation = df_new[['Arrival Delay (Minutes)','Origin Airport', 'Destination Airport']].corr()\n",
    "print(correlation)\n",
    "\n",
    "# Visualize correlation\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(correlation, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Between Origin Airpor & Destination Airport\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import load_model, pull, get_config, predict_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load saved model and pipeline\n",
    "model = load_model(\"best_regression_model\")\n",
    "\n",
    "target = \"Arrival Delay (Minutes)\"\n",
    "features = [\"Day\", \"Month\", \"Year\", \"Taxi-Out time (Minutes)\", \"Taxi-In time (Minutes)\", \"Scheduled Elapsed Time (Minutes)\",\n",
    "            \"Origin Airport\", \"Carrier Code\", \"Destination Airport\",\n",
    "            \"Scheduled departure hour\", \"Departure delay (Minutes)\"]\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Predict on training data\n",
    "train_preds_df = predict_model(model, data=X_train)\n",
    "train_preds = train_preds_df.iloc[:, -1].values  # Last column is prediction\n",
    "\n",
    "# Predict on test data\n",
    "test_preds_df = predict_model(model, data=X_test)\n",
    "test_preds = test_preds_df.iloc[:, -1].values\n",
    "\n",
    "# Compute metrics\n",
    "train_mae = mean_absolute_error(y_train, train_preds)\n",
    "test_mae = mean_absolute_error(y_test, test_preds)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_preds)\n",
    "test_mse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "train_r2 = r2_score(y_train, train_preds)\n",
    "test_r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "# Output results\n",
    "print(f\"ðŸ“Š PyCaret Model Performance:\")\n",
    "print(f\"   ðŸ”¹ Train MAE: {train_mae:.2f} min\")\n",
    "print(f\"   ðŸ”¹ Test MAE: {test_mae:.2f} min\")\n",
    "print(f\"   ðŸ”¹ Train MSE: {train_mse:.2f}\")\n",
    "print(f\"   ðŸ”¹ Test MSE: {test_mse:.2f}\")\n",
    "print(f\"   ðŸ”¹ Train RÂ²: {train_r2:.2f}\")\n",
    "print(f\"   ðŸ”¹ Test RÂ²: {test_r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2eddad",
   "metadata": {},
   "source": [
    "# **Deep Learning Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a1cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "# Define Features & Target\n",
    "target = \"Arrival Delay (Minutes)\"\n",
    "features = [\"Day\", \"Month\", \"Year\", \"Taxi-Out time (Minutes)\", \"Taxi-In time (Minutes)\",\n",
    "            \"Origin Airport\", \"Carrier Code\", \"Destination Airport\",\n",
    "            \"Scheduled Elapsed Time (Minutes)\",\n",
    "            \"Scheduled departure hour\", \"Departure delay (Minutes)\"]\n",
    "\n",
    "df = df[features + [target]].dropna()  # Drop missing values\n",
    "\n",
    "# âœ… One-Hot Encode Categorical Features\n",
    "categorical_features = [\"Origin Airport\", \"Carrier Code\", \"Destination Airport\"]\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "encoded_cats = encoder.fit_transform(df[categorical_features])\n",
    "joblib.dump(encoder, \"encoder.pkl\")\n",
    "\n",
    "# âœ… Standardize Numerical Features\n",
    "numerical_features = [\"Day\", \"Month\", \"Year\", \"Taxi-Out time (Minutes)\", \"Taxi-In time (Minutes)\",\n",
    "                      \"Scheduled Elapsed Time (Minutes)\",\n",
    "                      \"Scheduled departure hour\", \"Departure delay (Minutes)\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_numerics = scaler.fit_transform(df[numerical_features])\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# âœ… Combine Features\n",
    "X = np.hstack((scaled_numerics, encoded_cats))\n",
    "y = df[target].values\n",
    "\n",
    "print(f\"ðŸ“Š Final feature count: {X.shape[1]}\")  # Debugging feature count\n",
    "\n",
    "# âœ… Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# âœ… Train MLP (Neural Network) with improvements\n",
    "mlp_model = Sequential([\n",
    "    Dense(256, kernel_initializer=HeNormal(), input_shape=(X_train.shape[1],)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),  # Reduced from 0.3\n",
    "\n",
    "    Dense(128, kernel_initializer=HeNormal()),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.15),  # Reduced from 0.2\n",
    "\n",
    "    Dense(64, kernel_initializer=HeNormal()),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(32, kernel_initializer=HeNormal()),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "\n",
    "    Dense(1)  # Output Layer\n",
    "])\n",
    "\n",
    "# Compile with MAE loss and lower LR\n",
    "mlp_model.compile(optimizer=AdamW(learning_rate=0.001, weight_decay=1e-5),\n",
    "                  loss=\"mae\",  # Optimize MAE directly\n",
    "                  metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "# âœ… Callbacks for improved convergence\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-5, verbose=1)\n",
    "]\n",
    "\n",
    "# âœ… Train longer with smart control\n",
    "history = mlp_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,  # Longer training\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save Keras model in a compatible format\n",
    "mlp_model.save(\"mlp_model.keras\")\n",
    "# âœ… Evaluate Models\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "mlp_pred = mlp_model.predict(X_test).flatten()\n",
    "\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
    "mlp_mae = mean_absolute_error(y_test, mlp_pred)\n",
    "\n",
    "xgb_r2 = r2_score(y_test, xgb_pred)\n",
    "mlp_r2 = r2_score(y_test, mlp_pred)\n",
    "\n",
    "print(f\"ðŸ“‰ XGBoost MAE: {xgb_mae:.2f}, RÂ²: {xgb_r2:.2f}\")\n",
    "print(f\"ðŸ“‰ MLP Neural Network MAE: {mlp_mae:.2f}, RÂ²: {mlp_r2:.2f}\")\n",
    "\n",
    "# âœ… 95% Confidence Interval for MLP\n",
    "residuals = y_test - mlp_pred\n",
    "residual_std = np.std(residuals)\n",
    "ci_upper = mlp_pred + 1.96 * residual_std\n",
    "ci_lower = mlp_pred - 1.96 * residual_std\n",
    "\n",
    "print(f\"ðŸ“‰ Residual Std Dev: {residual_std:.2f}\")\n",
    "print(f\"ðŸ“‰ 95% Confidence Interval Range: Â±{1.96 * residual_std:.2f} min\")\n",
    "\n",
    "# âœ… Plot Training Loss & Validation Loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('MLP Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "\n",
    "# RÂ² Comparison Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "models = ['XGBoost', 'MLP']\n",
    "r2_scores = [xgb_r2, mlp_r2]\n",
    "plt.bar(models, r2_scores, color=['blue', 'green'])\n",
    "plt.title('Model RÂ² Comparison')\n",
    "plt.ylabel('RÂ² Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# âœ… Plot Prediction with 95% Confidence Interval\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test, label='Actual', alpha=0.7)\n",
    "plt.plot(mlp_pred, label='Predicted', alpha=0.7)\n",
    "plt.fill_between(np.arange(len(y_test)), ci_lower, ci_upper, color='orange', alpha=0.3, label='95% CI')\n",
    "plt.title('MLP Predictions with 95% Confidence Interval')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Arrival Delay (Minutes)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd97311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Updated MAPE function to handle zero values safely\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0  # Ignore zero values in y_true\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if np.any(mask) else np.inf\n",
    "\n",
    "# âœ… Predictions on Training & Test Data\n",
    "xgb_train_pred = xgb_model.predict(X_train)\n",
    "xgb_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "mlp_train_pred = mlp_model.predict(X_train).flatten()\n",
    "mlp_test_pred = mlp_model.predict(X_test).flatten()\n",
    "\n",
    "# âœ… Calculate MAE (Mean Absolute Error)\n",
    "xgb_train_mae = mean_absolute_error(y_train, xgb_train_pred)\n",
    "xgb_test_mae = mean_absolute_error(y_test, xgb_test_pred)\n",
    "\n",
    "mlp_train_mae = mean_absolute_error(y_train, mlp_train_pred)\n",
    "mlp_test_mae = mean_absolute_error(y_test, mlp_test_pred)\n",
    "\n",
    "# âœ… Calculate RÂ² Scores\n",
    "xgb_train_r2 = r2_score(y_train, xgb_train_pred)\n",
    "xgb_test_r2 = r2_score(y_test, xgb_test_pred)\n",
    "\n",
    "mlp_train_r2 = r2_score(y_train, mlp_train_pred)\n",
    "mlp_test_r2 = r2_score(y_test, mlp_test_pred)\n",
    "\n",
    "# âœ… Calculate MAPE (Mean Absolute Percentage Error) with zero handling\n",
    "xgb_train_mape = mean_absolute_percentage_error(y_train, xgb_train_pred)\n",
    "xgb_test_mape = mean_absolute_percentage_error(y_test, xgb_test_pred)\n",
    "\n",
    "mlp_train_mape = mean_absolute_percentage_error(y_train, mlp_train_pred)\n",
    "mlp_test_mape = mean_absolute_percentage_error(y_test, mlp_test_pred)\n",
    "\n",
    "# âœ… Print the Results\n",
    "print(f\"ðŸ“Š **XGBoost Performance:**\")\n",
    "print(f\"   - Train MAE: {xgb_train_mae:.2f} min\")\n",
    "print(f\"   - Test MAE: {xgb_test_mae:.2f} min\")\n",
    "print(f\"   - Train RÂ²: {xgb_train_r2:.2f}\")\n",
    "print(f\"   - Test RÂ²: {xgb_test_r2:.2f}\")\n",
    "print(f\"   - Train MAPE: {xgb_train_mape:.2f} %\")\n",
    "print(f\"   - Test MAPE: {xgb_test_mape:.2f} %\")\n",
    "\n",
    "print(f\"\\nðŸ“Š **MLP Neural Network Performance:**\")\n",
    "print(f\"   - Train MAE: {mlp_train_mae:.2f} min\")\n",
    "print(f\"   - Test MAE: {mlp_test_mae:.2f} min\")\n",
    "print(f\"   - Train RÂ²: {mlp_train_r2:.2f}\")\n",
    "print(f\"   - Test RÂ²: {mlp_test_r2:.2f}\")\n",
    "print(f\"   - Train MAPE: {mlp_train_mape:.2f} %\")\n",
    "print(f\"   - Test MAPE: {mlp_test_mape:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c78818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
